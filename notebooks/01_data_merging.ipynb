{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_data_merging.ipynb\n",
    "\n",
    "**Purpose:**\n",
    "Build a spatiotemporal modeling dataset to forecast human trafficking (HT) risk in NYC.\n",
    "\n",
    "**This notebook:**\n",
    "- Loads and cleans raw datasets (HT cases, HT crimes, events, passenger volumes).\n",
    "- Creates a comprehensive daily-location grid for modeling.\n",
    "- Engineers contextual features (crime density, event counts, holidays, etc).\n",
    "- Merges everything for downstream LSTM and spatiotemporal models.\n",
    "\n",
    "**Outputs:**\n",
    "A ready-to-model CSV/Feather file with millions of rows, each representing a specific location on a specific day, enriched with context features.\n",
    "\n",
    "> **Note:**  \n",
    "> Outputs are cleared for readability. Heavy computations are not re-executed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements: pandas, numpy, scikit-learn, holidays, tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import holidays\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load raw CSVs for HT cases, HT crimes, events, and passenger volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use relative paths as appropriate for your repo\n",
    "ht_cases = pd.read_csv('../data/sample/TAHub_NYC_Metro_Cases.csv', low_memory=False)\n",
    "ht_crimes = pd.read_csv('../data/sample/HT_RelatedCrimes_2021_2024.csv', low_memory=False)\n",
    "passenger_volume = pd.read_csv('../data/sample/Passenger_volume_JFKinbound_2021_2024.csv', low_memory=False)\n",
    "events = pd.read_csv('../data/sample/filtered_events_v2.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parsing and Cleaning Dates/Times\n",
    "Standardize and rename date/time columns for merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAHub Cases\n",
    "ht_cases['Incident Reporting Date'] = pd.to_datetime(ht_cases['Incident Reporting Date'])\n",
    "ht_cases = ht_cases.rename(columns={'Incident Reporting Date': 'date'})\n",
    "\n",
    "# HT Crimes\n",
    "ht_crimes['CMPLNT_FR_DT'] = pd.to_datetime(ht_crimes['CMPLNT_FR_DT'])\n",
    "ht_crimes = ht_crimes.rename(columns={'CMPLNT_FR_DT': 'date'})\n",
    "\n",
    "# Passenger Volume\n",
    "passenger_volume['Activity Period'] = pd.to_datetime(passenger_volume['Activity Period'])\n",
    "passenger_volume = passenger_volume.rename(columns={'Activity Period': 'month'})\n",
    "\n",
    "# Events\n",
    "events['start_date'] = pd.to_datetime(events['start_date'])\n",
    "events['end_date'] = pd.to_datetime(events['end_date'])\n",
    "events = events.rename(columns={'start_date': 'date'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering: Time Columns\n",
    "Extract features like hour and night flags from crimes and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HT Crimes - parse hour\n",
    "ht_crimes['crime_hour'] = pd.to_datetime(ht_crimes['CMPLNT_FR_TM'], format='%H:%M:%S', errors='coerce').dt.hour\n",
    "# Events - parse start and end hour\n",
    "events['event_start_hour'] = pd.to_datetime(events['start_time'], format='%H:%M:%S', errors='coerce').dt.hour\n",
    "events['event_end_hour'] = pd.to_datetime(events['end_time'], format='%H:%M:%S', errors='coerce').dt.hour\n",
    "\n",
    "# Night flags\n",
    "ht_crimes['is_night_crime'] = ht_crimes['crime_hour'].apply(lambda x: 1 if x in range(0, 6) else 0)\n",
    "events['is_night_event'] = events['event_start_hour'].apply(lambda x: 1 if x in range(0, 6) else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Location IDs\n",
    "Generate unique spatial IDs for each lat/lon pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_location_id(lat, lon):\n",
    "    return f\"{round(lat, 5)}_{round(lon, 5)}\"\n",
    "\n",
    "ht_cases['location_id'] = ht_cases.apply(lambda r: make_location_id(r['Latitude'], r['Longitude']), axis=1)\n",
    "ht_crimes['location_id'] = ht_crimes.apply(lambda r: make_location_id(r['Latitude'], r['Longitude']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Label Creation\n",
    "Create the binary target: Will an HT case occur at this location tomorrow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future label (future_ht_risk_1d)\n",
    "future_flags = []\n",
    "for loc, group in ht_cases.groupby('location_id'):\n",
    "    for report_date in group['date']:\n",
    "        future_flags.append((loc, report_date + pd.Timedelta(days=1)))\n",
    "risk_df = pd.DataFrame(future_flags, columns=['location_id', 'date'])\n",
    "risk_df['future_ht_risk_1d'] = 1\n",
    "\n",
    "df_label = ht_cases[['date', 'Latitude', 'Longitude', 'location_id']].copy()\n",
    "df_label = df_label.merge(risk_df, on=['location_id', 'date'], how='left')\n",
    "df_label['future_ht_risk_1d'] = df_label['future_ht_risk_1d'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Spatiotemporal Grid\n",
    "Cartesian product of all dates × all unique locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Gather all unique lat/lon pairs\n",
    "latlon_cases = ht_cases[['Latitude', 'Longitude']].dropna()\n",
    "latlon_crimes = ht_crimes[['Latitude', 'Longitude']].dropna()\n",
    "latlon_events = events[['Latitude', 'Longitude']].dropna() if 'Latitude' in events.columns else pd.DataFrame()\n",
    "\n",
    "all_locations = pd.concat([latlon_cases, latlon_crimes, latlon_events], ignore_index=True).drop_duplicates()\n",
    "all_locations['Latitude'] = all_locations['Latitude'].round(5)\n",
    "all_locations['Longitude'] = all_locations['Longitude'].round(5)\n",
    "all_locations['location_id'] = all_locations.apply(lambda r: make_location_id(r['Latitude'], r['Longitude']), axis=1)\n",
    "all_locations = all_locations.drop_duplicates(subset=['location_id'])\n",
    "\n",
    "# Date range\n",
    "min_date = min(ht_cases['date'].min(), ht_crimes['date'].min(), events['date'].min())\n",
    "max_date = max(ht_cases['date'].max(), ht_crimes['date'].max(), events['date'].max())\n",
    "all_dates = pd.date_range(start=min_date, end=max_date)\n",
    "\n",
    "# Cartesian product\n",
    "date_loc_grid = pd.DataFrame(list(product(all_dates, all_locations['location_id'])), columns=['date', 'location_id'])\n",
    "date_loc_grid = date_loc_grid.merge(all_locations, on='location_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merge Contextual Features\n",
    "- Event counts\n",
    "- Past 7-day spatial crime count\n",
    "- Night crime ratio\n",
    "- Passenger volume\n",
    "- Boroughs\n",
    "- Temporal features (weekday, season, holidays)\n",
    "- Supervised label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Merge Event Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_event_counts = events.groupby('date').size().reset_index(name='daily_event_count')\n",
    "date_loc_grid = date_loc_grid.merge(daily_event_counts, on='date', how='left')\n",
    "date_loc_grid['daily_event_count'] = date_loc_grid['daily_event_count'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Add Past 7-Day Crime Count (within 1 mile)\n",
    "Uses BallTree for efficient spatial queries.\n",
    "\n",
    "**Note:** This section is computationally expensive for large datasets. For portfolio, you do not need to rerun it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARTH_RADIUS_MILES = 3958.8\n",
    "search_radius_miles = 1\n",
    "search_radius_radians = search_radius_miles / EARTH_RADIUS_MILES\n",
    "\n",
    "# Prepare coordinates in radians\n",
    "ht_crimes = ht_crimes.dropna(subset=['Latitude', 'Longitude', 'date'])\n",
    "ht_crimes['lat_rad'] = np.radians(ht_crimes['Latitude'])\n",
    "ht_crimes['lon_rad'] = np.radians(ht_crimes['Longitude'])\n",
    "crime_coords_rad = ht_crimes[['lat_rad', 'lon_rad']].to_numpy()\n",
    "crime_dates = ht_crimes['date'].reset_index(drop=True)\n",
    "\n",
    "date_loc_grid['lat_rad'] = np.radians(date_loc_grid['Latitude'])\n",
    "date_loc_grid['lon_rad'] = np.radians(date_loc_grid['Longitude'])\n",
    "\n",
    "crime_tree = BallTree(crime_coords_rad, metric='haversine')\n",
    "crime_counts = []\n",
    "\n",
    "# Example: Only run on a small sample for illustration (remove or adjust for full run)\n",
    "# for i in tqdm(range(min(1000, len(date_loc_grid))), desc='Spatial 7d Crime Count'):\n",
    "#    ...\n",
    "# For full run, uncomment and beware of runtime\n",
    "# for i in tqdm(range(len(date_loc_grid)), desc='Spatial 7d Crime Count'):\n",
    "#    ...\n",
    "# date_loc_grid['past_7d_crime_count'] = crime_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Night Crime Ratio (past 7 days, within 1 mile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crime_hours = ht_crimes['crime_hour'].reset_index(drop=True)\n",
    "# night_ratios = []\n",
    "# for i in tqdm(range(len(date_loc_grid)), desc='Night Crime Ratio'):\n",
    "#    ...\n",
    "# date_loc_grid['night_crime_ratio'] = night_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Merge Monthly Passenger Volume (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'monthly_passenger_volume' not in passenger_volume.columns:\n",
    "    passenger_volume = passenger_volume.rename(columns={'Revenue Passenger Volume': 'monthly_passenger_volume'})\n",
    "\n",
    "date_loc_grid['month'] = date_loc_grid['date'].values.astype('datetime64[M]')\n",
    "date_loc_grid = date_loc_grid.merge(\n",
    "    passenger_volume[['month', 'monthly_passenger_volume']],\n",
    "    on='month',\n",
    "    how='left'\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "date_loc_grid['monthly_passenger_volume_scaled'] = scaler.fit_transform(\n",
    "    date_loc_grid[['monthly_passenger_volume']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5. Merge Boroughs\n",
    "First try from HT Crimes, then supplement with address extraction from TAHub cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_lookup = ht_crimes[['location_id', 'BORO_NM']].drop_duplicates()\n",
    "date_loc_grid = date_loc_grid.merge(borough_lookup, on='location_id', how='left')\n",
    "date_loc_grid = date_loc_grid.rename(columns={'BORO_NM': 'borough'})\n",
    "\n",
    "def extract_borough_from_address(address):\n",
    "    if pd.isna(address): return None\n",
    "    address = address.upper()\n",
    "    if \"BRONX\" in address: return \"BRONX\"\n",
    "    elif \"BROOKLYN\" in address: return \"BROOKLYN\"\n",
    "    elif \"QUEENS\" in address: return \"QUEENS\"\n",
    "    elif \"MANHATTAN\" in address or \"NEW YORK\" in address: return \"MANHATTAN\"\n",
    "    elif \"STATEN ISLAND\" in address: return \"STATEN ISLAND\"\n",
    "    else: return None\n",
    "ht_cases['borough_from_address'] = ht_cases['Address/Location'].apply(extract_borough_from_address)\n",
    "borough_lookup_tahub = ht_cases[['location_id', 'borough_from_address']].dropna().drop_duplicates()\n",
    "date_loc_grid = date_loc_grid.merge(borough_lookup_tahub, on='location_id', how='left')\n",
    "date_loc_grid['borough'] = date_loc_grid['borough'].fillna(date_loc_grid['borough_from_address'])\n",
    "date_loc_grid['borough'] = date_loc_grid['borough'].fillna(\"Unknown\")\n",
    "date_loc_grid = date_loc_grid.drop(columns=['borough_from_address'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6. Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_loc_grid['day_of_week'] = date_loc_grid['date'].dt.dayofweek  # Monday=0\n",
    "date_loc_grid['is_weekend'] = date_loc_grid['day_of_week'].isin([5, 6]).astype(int)\n",
    "date_loc_grid['month_num'] = date_loc_grid['date'].dt.month\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]: return 'Winter'\n",
    "    elif month in [3, 4, 5]: return 'Spring'\n",
    "    elif month in [6, 7, 8]: return 'Summer'\n",
    "    else: return 'Fall'\n",
    "date_loc_grid['season'] = date_loc_grid['month_num'].apply(get_season)\n",
    "\n",
    "us_holidays = holidays.US(years=range(date_loc_grid['date'].dt.year.min(), date_loc_grid['date'].dt.year.max()+1))\n",
    "date_loc_grid['is_holiday'] = date_loc_grid['date'].isin(us_holidays).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7. Merge Supervised Label (future_ht_risk_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = df_label[['date', 'location_id', 'future_ht_risk_1d']].drop_duplicates()\n",
    "date_loc_grid = date_loc_grid.merge(label_df, on=['date', 'location_id'], how='left')\n",
    "date_loc_grid['future_ht_risk_1d'] = date_loc_grid['future_ht_risk_1d'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8. Final Clean-up (drop duplicate/raw columns, check missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_loc_grid = date_loc_grid.drop(\n",
    "    columns=['monthly_passenger_volume', 'monthly_passenger_volume_x', 'monthly_passenger_volume_y',\n",
    "            'month_num', 'lat_rad', 'lon_rad'], errors='ignore')\n",
    "missing = date_loc_grid.isnull().sum()\n",
    "print(\"Missing values (should all be zero):\\n\", missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Final Dataset\n",
    "Write output for modeling. Use feather for fast reloads; csv for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_loc_grid.to_feather(\"../data/final_modeling_dataset_v2.feather\")\n",
    "date_loc_grid.to_csv(\"../data/final_modeling_dataset_v2.csv\", index=False)\n",
    "print(f\"✅ Saved final dataset: {date_loc_grid.shape} (feather & csv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Dictionary\n",
    "\n",
    "| Column                         | Description                                               |\n",
    "|--------------------------------|-----------------------------------------------------------|\n",
    "| date                           | Day (YYYY-MM-DD)                                         |\n",
    "| location_id                    | Rounded lat/lon identifier (e.g., '40.78343_-73.96625')  |\n",
    "| Latitude, Longitude            | Spatial coordinates                                      |\n",
    "| past_7d_crime_count            | Crimes within 1mi, past 7 days                           |\n",
    "| night_crime_ratio              | Ratio of night crimes among past 7d crimes                |\n",
    "| daily_event_count              | Number of city-permitted events that day                  |\n",
    "| monthly_passenger_volume_scaled| Scaled inbound passenger volume (JFK)                     |\n",
    "| borough                        | NYC borough                                              |\n",
    "| day_of_week                    | Day of week (0=Mon)                                      |\n",
    "| is_weekend                     | 1 if Saturday/Sunday, else 0                              |\n",
    "| season                         | Season name                                              |\n",
    "| is_holiday                     | 1 if US holiday, else 0                                  |\n",
    "| future_ht_risk_1d              | 1 if HT case next day at location, else 0 (label)        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507032fe",
   "metadata": {},
   "source": [
    "**Next Steps:**  \n",
    "- Exploratory data analysis (EDA) and visualizations were performed within this notebook and in the modeling notebook.\n",
    "- See the modeling notebook (`02_modeling.ipynb`) for predictive modeling and further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
